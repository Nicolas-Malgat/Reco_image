{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Import"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Environement actuel:  image\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "print('Environement actuel: ', os.environ['CONDA_DEFAULT_ENV'])\n",
    "\n",
    "from modules.timer import Timer\n",
    "timer = Timer()"
   ]
  },
  {
   "source": [
    "## Chargement des images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "0.0015 - 0.0025 s pour la lecture d'une image\n",
    "\n",
    "```\n",
    "Elapsed time: 0.0022 seconds\n",
    "(32, 32, 3)\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Elapsed time: 0.0018 seconds\n(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "timer.start()\n",
    "im = cv2.imread('../datas/RAW/train/chair/0001.png')\n",
    "timer.stop()\n",
    "\n",
    "print(im.shape)\n",
    "TRAIN_IMAGE_SIZE = im.shape[0]"
   ]
  },
  {
   "source": [
    "lalecture de 500 images dure 0.3 seconde\n",
    "\n",
    "```\n",
    "Elapsed time: 0.3223 seconds\n",
    "500\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Elapsed time: 0.3315 seconds\n500\n"
     ]
    }
   ],
   "source": [
    "chairs = '../datas/RAW/train/chair/'\n",
    "mes_chaises = os.listdir(chairs)\n",
    "\n",
    "timer.start()\n",
    "for i in range(500):\n",
    "    # print(chairs + mes_chaises[i])\n",
    "    cv2.imread(chairs + mes_chaises[i])\n",
    "timer.stop()\n",
    "\n",
    "print(len(mes_chaises))"
   ]
  },
  {
   "source": [
    "Il y a 100 dossiers, tous les dossiers ont 500 images\n",
    "soit 50 000 images\n",
    "\n",
    "la lecture de la totalite des images est estimee a (500*100=50 000) soit 30 secondes ou une minute pour etre large"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100\n500\n"
     ]
    }
   ],
   "source": [
    "train_folder = '../datas/RAW/train/'\n",
    "\n",
    "dossiers = os.listdir(train_folder)\n",
    "print(len(dossiers))\n",
    "\n",
    "for i in range(1):\n",
    "    imgs = os.listdir(train_folder + dossiers[i])\n",
    "    print(len(imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.2)\n",
    "\n",
    "# TRAIN_DATA_DIR = '../data/dataset'\n",
    "# # TRAIN_IMAGE_SIZE = 28\n",
    "# TRAIN_BATCH_SIZE = 32\n",
    "\n",
    "# train_generator = image_data_generator.flow_from_directory(\n",
    "#     TRAIN_DATA_DIR,\n",
    "#     target_size=(TRAIN_IMAGE_SIZE, TRAIN_IMAGE_SIZE),\n",
    "#     batch_size=TRAIN_BATCH_SIZE,\n",
    "#     class_mode='categorical',\n",
    "#     subset='training')\n",
    " \n",
    "# validation_generator = image_data_generator.flow_from_directory(\n",
    "#     TRAIN_DATA_DIR, # same directory as training data\n",
    "#     target_size=(TRAIN_IMAGE_SIZE, TRAIN_IMAGE_SIZE),\n",
    "#     batch_size=TRAIN_BATCH_SIZE,\n",
    "#     class_mode='categorical',\n",
    "#     subset='validation')"
   ]
  },
  {
   "source": [
    "## Creation modele"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(32, kernel_size=7, activation='relu', padding='same', input_shape=(28,28,3))) # 5 ou 7 au dessus de 128\n",
    "# model.add(Conv2D(64, kernel_size=7, activation='relu', padding='same'))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# model.summary()"
   ]
  }
 ]
}