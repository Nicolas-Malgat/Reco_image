{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('image': conda)",
   "metadata": {
    "interpreter": {
     "hash": "bbe788757d06f51469906cd2e49eb863c74a894ffdb2c30a992d00a1cc2156b7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Import"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Envirronement actuel:  image\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('Environement actuel: ', os.environ['CONDA_DEFAULT_ENV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "DLL load failed: Le module spécifié est introuvable.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2e188c8a350f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: Le module spécifié est introuvable."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "source": [
    "## Chargement des images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread('../datas/RAW/train/chair/0001.png')\n",
    "\n",
    "print(im.shape)\n",
    "print(type(im.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chairs = '../datas/RAW/train/chair/'\n",
    "mes_chaises = os.listdir(chairs)\n",
    "\n",
    "for chaise in mes_chaises:\n",
    "    print(chaise.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.2)\n",
    "\n",
    "TRAIN_DATA_DIR = '../data/dataset'\n",
    "TRAIN_IMAGE_SIZE = 28\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "\n",
    "train_generator = image_data_generator.flow_from_directory(\n",
    "    TRAIN_DATA_DIR,\n",
    "    target_size=(TRAIN_IMAGE_SIZE, TRAIN_IMAGE_SIZE),\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training')\n",
    " \n",
    "validation_generator = image_data_generator.flow_from_directory(\n",
    "    TRAIN_DATA_DIR, # same directory as training data\n",
    "    target_size=(TRAIN_IMAGE_SIZE, TRAIN_IMAGE_SIZE),\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')"
   ]
  },
  {
   "source": [
    "## Creation modele"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=7, activation='relu', padding='same', input_shape=(28,28,3))) # 5 ou 7 au dessus de 128\n",
    "model.add(Conv2D(64, kernel_size=7, activation='relu', padding='same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  }
 ]
}