{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Import"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from modules.prediction_image import resize_image, evaluate, stackImages, getContours, empty, redimensionner\n",
    "\n",
    "model = load_model('model.h5')\n"
   ]
  },
  {
   "source": [
    "## Test du modele"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Img 0001.png. Cet objet est un(e) \"apple\".\n",
      "bee:\t 0.0 %\n",
      "apple:\t 100.0 %\n",
      "\n",
      "Img 0002.png. Cet objet est un(e) \"apple\".\n",
      "bee:\t 0.7000000216066837 %\n",
      "apple:\t 99.29999709129333 %\n",
      "\n",
      "Img 0003.png. Cet objet est un(e) \"apple\".\n",
      "bee:\t 0.0 %\n",
      "apple:\t 100.0 %\n",
      "\n",
      "Img 0004.png. Cet objet est un(e) \"bee\".\n",
      "apple:\t 0.0 %\n",
      "bee:\t 100.0 %\n",
      "\n",
      "Img 0005.png. Cet objet est un(e) \"apple\".\n",
      "bee:\t 0.0 %\n",
      "apple:\t 100.0 %\n",
      "\n",
      "Img 0001.png. Cet objet est un(e) \"bee\".\n",
      "apple:\t 1.4999999664723873 %\n",
      "bee:\t 98.50000143051147 %\n",
      "\n",
      "Img 0002.png. Cet objet est un(e) \"bee\".\n",
      "apple:\t 0.0 %\n",
      "bee:\t 100.0 %\n",
      "\n",
      "Img 0003.png. Cet objet est un(e) \"bee\".\n",
      "apple:\t 0.10000000474974513 %\n",
      "bee:\t 99.90000128746033 %\n",
      "\n",
      "Img 0004.png. Cet objet est un(e) \"bee\".\n",
      "apple:\t 5.000000074505806 %\n",
      "bee:\t 94.9999988079071 %\n",
      "\n",
      "Img 0005.png. Cet objet est un(e) \"apple\".\n",
      "bee:\t 0.20000000949949026 %\n",
      "apple:\t 99.80000257492065 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model.h5')\n",
    "\n",
    "label_array = ['apple', 'bee']\n",
    "choix = [\n",
    "    'assets/apple/0001.png'\n",
    "    , 'assets/apple/0002.png'\n",
    "    , 'assets/apple/0003.png'\n",
    "    , 'assets/apple/0004.png'\n",
    "    , 'assets/apple/0005.png'\n",
    "    , 'assets/bee/0001.png'\n",
    "    , 'assets/bee/0002.png'\n",
    "    , 'assets/bee/0003.png'\n",
    "    , 'assets/bee/0004.png'\n",
    "    , 'assets/bee/0005.png'\n",
    "]\n",
    "\n",
    "for c in choix:\n",
    "    test_image = image.load_img(c, target_size = (32, 32))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = model.predict(test_image)\n",
    "\n",
    "    preds = model.predict_classes(test_image)\n",
    "    prob = model.predict_proba(test_image)\n",
    "\n",
    "    index = preds[0]\n",
    "    img = c.split('/')[-1]\n",
    "    print(f'Img {img}. Cet objet est un(e) \"{label_array[index]}\".')\n",
    "\n",
    "    prob_sort = np.argsort(prob[0])[-2:]\n",
    "\n",
    "    for ps in prob_sort:\n",
    "        proba = prob[0][ps]\n",
    "        label = label_array[ps]\n",
    "        print(f'{label}:\\t', round(proba, 3)*100, '%' )\n",
    "\n",
    "    print()"
   ]
  },
  {
   "source": [
    "## Detection d'objet avec openCV"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"assets/image_internet/\"\n",
    "\n",
    "img_originale = cv2.imread(path + \"pomme_plusieurs.jpg\")\n",
    "img_originale = redimensionner(img_originale, 400)\n",
    "\n",
    "Threshold1 = 80\n",
    "Threshold2 = 80\n",
    "AreaMin = 1000\n",
    "AreaMax = 100000"
   ]
  },
  {
   "source": [
    "## Reglages sur la detection d'objet"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"Parameters\")\n",
    "cv2.resizeWindow(\"Parameters\", 640, 240)\n",
    "cv2.createTrackbar(\"Threshold1\", \"Parameters\",   Threshold1, 255, empty)\n",
    "cv2.createTrackbar(\"Threshold2\", \"Parameters\",   Threshold2, 255, empty)\n",
    "cv2.createTrackbar(\"AreaMin\", \"Parameters\",      AreaMin, 3000, empty)\n",
    "cv2.createTrackbar(\"AreaMax\", \"Parameters\",      AreaMax, 150000, empty)\n",
    "\n",
    "img = img_originale\n",
    "\n",
    "while True:\n",
    "\n",
    "    imgContour = img.copy()\n",
    "    imgBlur = cv2.GaussianBlur(img, (9, 9), 1)\n",
    "    threshold1 = cv2.getTrackbarPos(\"Threshold1\", \"Parameters\")\n",
    "    threshold2 = cv2.getTrackbarPos(\"Threshold2\", \"Parameters\")\n",
    "    imgCanny = cv2.Canny(imgBlur, threshold1, threshold2)\n",
    "    kernel = np.ones((2, 2))\n",
    "    imgDil = cv2.dilate(imgCanny, kernel, iterations=1)\n",
    "    getContours(imgDil, imgContour)\n",
    "    imgStack = stackImages(0.8, ([img,imgCanny], [imgDil,imgContour]) )\n",
    "\n",
    "    cv2.imshow(\"Result\", imgStack)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "source": [
    "## Decoupage et prediction des objets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "bee\n",
      "bee\n",
      "bee\n",
      "bee\n",
      "bee\n",
      "bee\n",
      "bee\n",
      "bee\n"
     ]
    }
   ],
   "source": [
    "img_traite = img_originale.copy()\n",
    "\n",
    "imgBlur = cv2.GaussianBlur(img_traite, (9, 9), 1)\n",
    "imgCanny = cv2.Canny(imgBlur, Threshold1, Threshold2)\n",
    "imgDil = cv2.dilate(imgCanny, np.ones((2, 2)), iterations=1)\n",
    "\n",
    "contours = cv2.findContours(imgDil, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "contours = [cnt for cnt in contours if cv2.contourArea(cnt) > AreaMin and cv2.contourArea(cnt) < AreaMax]\n",
    "\n",
    "img_affichage = img_traite.copy()\n",
    "\n",
    "for cnt in contours:\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    img = img_traite[y:y+h, x:x+w]\n",
    "\n",
    "    img = resize_image(img)\n",
    "\n",
    "    predictions = list()\n",
    "    label = evaluate(model, img, label_array)\n",
    "    print(label)\n",
    "\n",
    "    cv2.putText(img_affichage, label, (x-10, y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "    cv2.rectangle(img_affichage, (x , y ), (x + w , y + h ), (0, 0, 255), 5)\n",
    "\n",
    "cv2.imshow(\"image\", img_affichage)\n",
    "cv2.waitKey()\n",
    "cv2.destroyWindow(\"image\")"
   ]
  }
 ]
}