{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Import"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "source": [
    "## Test du modele"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Img 0001.png. Cet objet est un(e) \"apple\".\n",
      "bee:\t 0.0\n",
      "apple:\t 1.0\n",
      "\n",
      "Img 0002.png. Cet objet est un(e) \"apple\".\n",
      "bee:\t 0.007\n",
      "apple:\t 0.993\n",
      "\n",
      "Img 0003.png. Cet objet est un(e) \"apple\".\n",
      "bee:\t 0.0\n",
      "apple:\t 1.0\n",
      "\n",
      "Img 0004.png. Cet objet est un(e) \"bee\".\n",
      "apple:\t 0.0\n",
      "bee:\t 1.0\n",
      "\n",
      "Img 0005.png. Cet objet est un(e) \"apple\".\n",
      "bee:\t 0.0\n",
      "apple:\t 1.0\n",
      "\n",
      "Img 0001.png. Cet objet est un(e) \"bee\".\n",
      "apple:\t 0.015\n",
      "bee:\t 0.985\n",
      "\n",
      "Img 0002.png. Cet objet est un(e) \"bee\".\n",
      "apple:\t 0.0\n",
      "bee:\t 1.0\n",
      "\n",
      "Img 0003.png. Cet objet est un(e) \"bee\".\n",
      "apple:\t 0.001\n",
      "bee:\t 0.999\n",
      "\n",
      "Img 0004.png. Cet objet est un(e) \"bee\".\n",
      "apple:\t 0.05\n",
      "bee:\t 0.95\n",
      "\n",
      "Img 0005.png. Cet objet est un(e) \"apple\".\n",
      "bee:\t 0.002\n",
      "apple:\t 0.998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model.h5')\n",
    "\n",
    "labels_array = ['apple', 'bee']\n",
    "choix = [\n",
    "    'assets/apple/0001.png'\n",
    "    , 'assets/apple/0002.png'\n",
    "    , 'assets/apple/0003.png'\n",
    "    , 'assets/apple/0004.png'\n",
    "    , 'assets/apple/0005.png'\n",
    "    , 'assets/bee/0001.png'\n",
    "    , 'assets/bee/0002.png'\n",
    "    , 'assets/bee/0003.png'\n",
    "    , 'assets/bee/0004.png'\n",
    "    , 'assets/bee/0005.png'\n",
    "]\n",
    "\n",
    "for c in choix:\n",
    "    test_image = image.load_img(c, target_size = (32, 32))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = model.predict(test_image)\n",
    "\n",
    "    preds = model.predict_classes(test_image)\n",
    "    prob = model.predict_proba(test_image)\n",
    "\n",
    "    index = preds[0]\n",
    "    img = c.split('/')[-1]\n",
    "    print(f'Img {img}. Cet objet est un(e) \"{labels_array[index]}\".')\n",
    "\n",
    "    prob_sort = np.argsort(prob[0])[-2:]\n",
    "\n",
    "    for ps in prob_sort:\n",
    "        proba = prob[0][ps]\n",
    "        label = labels_array[ps]\n",
    "        print(f'{label}:\\t', round(proba, 3) )\n",
    "\n",
    "    print()"
   ]
  },
  {
   "source": [
    "## Chargement de opencv"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from tensorflow.keras.models import load_model\r\n",
    "\r\n",
    "from modules.prediction_image import resize_image, evaluate, stackImages, getContours, empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"assets/image_internet/\"\n",
    "\n",
    "img_originale = cv2.imread(path + \"pomme.jpg\")\n",
    "\n",
    "model = load_model('model.h5')\n",
    "\n",
    "Threshold1 = 150\n",
    "Threshold2 = 150\n",
    "AreaMin = 850\n",
    "AreaMax = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(211, 375, 3)\n(211, 375, 3)\n(211, 375, 3)\n"
     ]
    }
   ],
   "source": [
    "img_traite = img_originale.copy()\n",
    "\n",
    "imgBlur = cv2.GaussianBlur(img_traite, (9, 9), 1)\n",
    "# img_traite = cv2.cvtColor(img_traite, cv2.COLOR_BGR2GRAY)\n",
    "imgCanny = cv2.Canny(img_traite, Threshold1, Threshold2)\n",
    "kernel = np.ones((5, 5))\n",
    "imgDil = cv2.dilate(imgCanny, kernel, iterations=1)\n",
    "\n",
    "cv2.imshow(\"image\", imgDil)\n",
    "cv2.waitKey()\n",
    "cv2.destroyWindow(\"image\")\n",
    "\n",
    "contours = cv2.findContours(imgDil, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "contours = [cnt for cnt in contours if cv2.contourArea(cnt) > AreaMin and cv2.contourArea(cnt) < AreaMax]\n",
    "\n",
    "img_affichage = img_traite.copy()\n",
    "\n",
    "for cnt in contours:\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    img = img_affichage[y:y+h, x:x+w]\n",
    "\n",
    "    img = cv2.bitwise_not(img)\n",
    "    img = resize_image(img)\n",
    "    \n",
    "    cv2.imshow(\"image\", img)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyWindow(\"image\")\n",
    "\n",
    "    img = cv2.copyMakeBorder(img, 4, 4, 4, 4, cv2.BORDER_CONSTANT)\n",
    "\n",
    "    predictions = list()\n",
    "    label = evaluate(img)\n",
    "\n",
    "    cv2.putText(img_affichage, label, (x-10, y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "    cv2.rectangle(img_affichage, (x , y ), (x + w , y + h ), (0, 0, 255), 5)\n",
    "\n",
    "print(img_originale.shape)\n",
    "print(img_traite.shape)\n",
    "print(img_affichage.shape)\n",
    "\n",
    "cv2.imshow(\"image\", img_affichage)\n",
    "cv2.waitKey()\n",
    "cv2.destroyWindow(\"image\")\n",
    "del(img_traite, imgCanny, img, img_affichage)"
   ]
  },
  {
   "source": [
    "## Reglages sur l'image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.namedWindow(\"Parameters\")\n",
    "# cv2.resizeWindow(\"Parameters\", 640, 240)\n",
    "# cv2.createTrackbar(\"Threshold1\", \"Parameters\",   Threshold1, 255, empty)\n",
    "# cv2.createTrackbar(\"Threshold2\", \"Parameters\",   Threshold2, 255, empty)\n",
    "# cv2.createTrackbar(\"AreaMin\", \"Parameters\",      AreaMin, 3000, empty)\n",
    "# cv2.createTrackbar(\"AreaMax\", \"Parameters\",      AreaMax, 50000, empty)\n",
    "\n",
    "# img = img_originale\n",
    "\n",
    "# while True:\n",
    "\n",
    "#     imgContour = img.copy()\n",
    "#     imgBlur = cv2.GaussianBlur(img, (9, 9), 1)\n",
    "#     imgGray = cv2.cvtColor(imgBlur, cv2.COLOR_BGR2GRAY)\n",
    "#     threshold1 = cv2.getTrackbarPos(\"Threshold1\", \"Parameters\")\n",
    "#     threshold2 = cv2.getTrackbarPos(\"Threshold2\", \"Parameters\")\n",
    "#     imgCanny = cv2.Canny(imgGray, threshold1, threshold2)\n",
    "#     kernel = np.ones((5, 5))\n",
    "#     imgDil = cv2.dilate(imgCanny, kernel, iterations=1)\n",
    "#     getContours(imgDil, imgContour)\n",
    "#     imgStack = stackImages(0.8, ([img,imgCanny], [imgDil,imgContour]) )\n",
    "\n",
    "#     cv2.imshow(\"Result\", imgStack)\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  }
 ]
}